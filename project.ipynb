{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_p(x, p):\n",
    "    '''\n",
    "    Prox-function\n",
    "    '''\n",
    "    return 1 / (p + 1) * x**(p + 1)\n",
    "\n",
    "\n",
    "def hessian_vector_product(f, x, v):\n",
    "    '''\n",
    "    Hessian-vector product: D^2(f) @ v\n",
    "    '''\n",
    "    grad_f = torch.autograd.grad([f(x)], [x], create_graph=True)[0]\n",
    "    z = grad_f @ v\n",
    "    z.backward()\n",
    "    return x.grad\n",
    "\n",
    "\n",
    "def BDGM(f, x_tilda_k, delta, L3):\n",
    "    \n",
    "    grad_f_x_tilda_k = torch.autograd.grad([f(x_tilda_k)], [x_tilda_k], create_graph=True)[0]\n",
    "    \n",
    "    z_0 = x_tilda_k\n",
    "    tau = 3 * delta / (8 * (2 + math.sqrt(2)) * torch.norm(grad_f))\n",
    "    \n",
    "    def D2v(z):\n",
    "        return hessian_vector_product(f, x_tilda_k, z - x_tilda_k)\n",
    "    \n",
    "    def rho_k(z):\n",
    "        '''\n",
    "        Scaling function\n",
    "        '''\n",
    "        return .5 * D2v(f, x_tilda_k, z - x_tilda_k) @ (z - x_tilda_k) \\\n",
    "               + L3 * d_p(z - x_tilda_k, 4)\n",
    "    \n",
    "    def beta_rho_k(z_i, z):\n",
    "        '''\n",
    "        Bregman distance\n",
    "        '''\n",
    "        grad_rho_k = torch.autograd.grad([rho_k(z)])\n",
    "        return rho_k(z) - rho_k(z_i) - grad_rho_k @ (z - z_i)\n",
    "    \n",
    "    def g_x_tilda_k_tau(z):\n",
    "        grad_g_p = torch.autograd.grad([f(x_tilda_k + tau * (z - x_tilda_k))], [x], create_graph=True)[0]\n",
    "        grad_g_n = torch.autograd.grad([f(x_tilda_k - tau * (z - x_tilda_k))], [x], create_graph=True)[0]\n",
    "        return 1 / tau**2 * (grad_g_p + grad_g_n - 2 * grad_f_x_tilda_k)\n",
    "    \n",
    "    def g_phi_k_tau(z):\n",
    "        return grad_f_x_tilda_k + D2v(z) + g_x_tilda_k_tau(z) + L3 * ((z - x_tilda_k)**2).sum() * (z - x_tilda_k)\n",
    "    \n",
    "    i = 0\n",
    "    z_i = z_0\n",
    "    while True:\n",
    "        g_phi_k_tau_z_i = g_phi_k_tau(z_i)\n",
    "        grad_f_z_i = torch.autograd.grad([f(z_i)], [z_i], create_graph=True)[0]\n",
    "        if torch.norm(g_phi_k_tau_z_i) < 1 / 6 * torch.norm(grad_f_z_i) - delta:\n",
    "            break\n",
    "        else:\n",
    "            \n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.1000], requires_grad=True)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = torch.Tensor([1, 1])\n",
    "v.requires_grad_()\n",
    "\n",
    "x = torch.Tensor([0.1, 0.1])\n",
    "x.requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 3 * x[0] ** 2 + 4 * x[0] * x[1] + x[1] **2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.,  6.])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D2v(f, x, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.,  6.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = torch.Tensor([1, 1])\n",
    "v.requires_grad_()\n",
    "\n",
    "x = torch.Tensor([0.1, 0.1])\n",
    "x.requires_grad_()\n",
    "\n",
    "f = 3 * x[0] ** 2 + 4 * x[0] * x[1] + x[1] **2\n",
    "\n",
    "grad_f, = torch.autograd.grad([f], [x], create_graph=True)\n",
    "z = grad_f @ v\n",
    "z.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0800, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.0000, 0.6000], grad_fn=<AddBackward0>),)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1.], requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6000, grad_fn=<DotBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6000, grad_fn=<DotBackward>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v @ grad_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
